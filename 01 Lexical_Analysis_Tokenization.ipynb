{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240b68c2-cf1f-4231-acc2-80973b4d3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python`\n",
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de084d0-bac9-4ad5-8b5b-36d2f276119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk spacy textblob -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776710e3-cd03-47e7-b22d-756be9bf33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, MWETokenizer, WhitespaceTokenizer\n",
    "from nltk.tokenize import SpaceTokenizer, TabTokenizer, LineTokenizer, TweetTokenizer\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2efe1e6-e248-4e03-9605-3dc339bed998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package indian to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #tokenization\n",
    "nltk.download('stopwords') #stopwords removal\n",
    "nltk.download('averaged_perceptron_tagger') #POS tagging\n",
    "nltk.download('wordnet') #wordnet database and lemmatization\n",
    "nltk.download('omw-1.4') #stemming\n",
    "nltk.download('indian') #Indian language POS tagging\n",
    "nltk.download('maxent_ne_chunker') #chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c1419-aad2-4f35-af71-ba08bc0b853d",
   "metadata": {},
   "source": [
    "### sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8775cb-5d62-4c84-a66f-bba94f50b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'They told that their ages are 25 27 and 31 respectively.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c505bd-4a3d-46cf-81a4-f820184f7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the average of ages mentioned in the sentence above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ba8d6f-5914-4697-b935-6353464f9fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class str in module builtins:\n",
      "\n",
      "class str(object)\n",
      " |  str(object='') -> str\n",
      " |  str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
      " |  \n",
      " |  Create a new string object from the given object. If encoding or\n",
      " |  errors is specified, then the object must expose a data buffer\n",
      " |  that will be decoded using the given encoding and error handler.\n",
      " |  Otherwise, returns the result of object.__str__() (if defined)\n",
      " |  or repr(object).\n",
      " |  encoding defaults to sys.getdefaultencoding().\n",
      " |  errors defaults to 'strict'.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Return a formatted version of the string as described by format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the string in memory, in bytes.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(self, /)\n",
      " |      Return a capitalized version of the string.\n",
      " |      \n",
      " |      More specifically, make the first character have upper case and the rest lower\n",
      " |      case.\n",
      " |  \n",
      " |  casefold(self, /)\n",
      " |      Return a version of the string suitable for caseless comparisons.\n",
      " |  \n",
      " |  center(self, width, fillchar=' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are\n",
      " |      interpreted as in slice notation.\n",
      " |  \n",
      " |  encode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Encode the string using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding in which to encode the string.\n",
      " |      errors\n",
      " |        The error handling scheme to use for encoding errors.\n",
      " |        The default is 'strict' meaning that encoding errors raise a\n",
      " |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      " |        'xmlcharrefreplace' as well as any other name registered with\n",
      " |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  format_map(...)\n",
      " |      S.format_map(mapping) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from mapping.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(self, /)\n",
      " |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isalpha(self, /)\n",
      " |      Return True if the string is an alphabetic string, False otherwise.\n",
      " |      \n",
      " |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isascii(self, /)\n",
      " |      Return True if all characters in the string are ASCII, False otherwise.\n",
      " |      \n",
      " |      ASCII characters have code points in the range U+0000-U+007F.\n",
      " |      Empty string is ASCII too.\n",
      " |  \n",
      " |  isdecimal(self, /)\n",
      " |      Return True if the string is a decimal string, False otherwise.\n",
      " |      \n",
      " |      A string is a decimal string if all characters in the string are decimal and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isdigit(self, /)\n",
      " |      Return True if the string is a digit string, False otherwise.\n",
      " |      \n",
      " |      A string is a digit string if all characters in the string are digits and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isidentifier(self, /)\n",
      " |      Return True if the string is a valid Python identifier, False otherwise.\n",
      " |      \n",
      " |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,\n",
      " |      such as \"def\" or \"class\".\n",
      " |  \n",
      " |  islower(self, /)\n",
      " |      Return True if the string is a lowercase string, False otherwise.\n",
      " |      \n",
      " |      A string is lowercase if all cased characters in the string are lowercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  isnumeric(self, /)\n",
      " |      Return True if the string is a numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is numeric if all characters in the string are numeric and there is at\n",
      " |      least one character in the string.\n",
      " |  \n",
      " |  isprintable(self, /)\n",
      " |      Return True if the string is printable, False otherwise.\n",
      " |      \n",
      " |      A string is printable if all of its characters are considered printable in\n",
      " |      repr() or if it is empty.\n",
      " |  \n",
      " |  isspace(self, /)\n",
      " |      Return True if the string is a whitespace string, False otherwise.\n",
      " |      \n",
      " |      A string is whitespace if all characters in the string are whitespace and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  istitle(self, /)\n",
      " |      Return True if the string is a title-cased string, False otherwise.\n",
      " |      \n",
      " |      In a title-cased string, upper- and title-case characters may only\n",
      " |      follow uncased characters and lowercase characters only cased ones.\n",
      " |  \n",
      " |  isupper(self, /)\n",
      " |      Return True if the string is an uppercase string, False otherwise.\n",
      " |      \n",
      " |      A string is uppercase if all cased characters in the string are uppercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  join(self, iterable, /)\n",
      " |      Concatenate any number of strings.\n",
      " |      \n",
      " |      The string whose method is called is inserted in between each given string.\n",
      " |      The result is returned as a new string.\n",
      " |      \n",
      " |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      " |  \n",
      " |  ljust(self, width, fillchar=' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(self, /)\n",
      " |      Return a copy of the string converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string.  If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original string\n",
      " |      and two empty strings.\n",
      " |  \n",
      " |  removeprefix(self, prefix, /)\n",
      " |      Return a str with the given prefix string removed if present.\n",
      " |      \n",
      " |      If the string starts with the prefix string, return string[len(prefix):].\n",
      " |      Otherwise, return a copy of the original string.\n",
      " |  \n",
      " |  removesuffix(self, suffix, /)\n",
      " |      Return a str with the given suffix string removed if present.\n",
      " |      \n",
      " |      If the string ends with the suffix string and that suffix is not empty,\n",
      " |      return string[:-len(suffix)]. Otherwise, return a copy of the original\n",
      " |      string.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      " |      and the original string.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the substrings in the string, using sep as the separator string.\n",
      " |      \n",
      " |        sep\n",
      " |          The separator used to split the string.\n",
      " |      \n",
      " |          When set to None (the default value), will split on any whitespace\n",
      " |          character (including \\n \\r \\t \\f and spaces) and will discard\n",
      " |          empty strings from the result.\n",
      " |        maxsplit\n",
      " |          Maximum number of splits (starting from the left).\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splitting starts at the end of the string and works to the front.\n",
      " |  \n",
      " |  rstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the substrings in the string, using sep as the separator string.\n",
      " |      \n",
      " |        sep\n",
      " |          The separator used to split the string.\n",
      " |      \n",
      " |          When set to None (the default value), will split on any whitespace\n",
      " |          character (including \\n \\r \\t \\f and spaces) and will discard\n",
      " |          empty strings from the result.\n",
      " |        maxsplit\n",
      " |          Maximum number of splits (starting from the left).\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Note, str.split() is mainly useful for data that has been intentionally\n",
      " |      delimited.  With natural text that includes punctuation, consider using\n",
      " |      the regular expression module.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the string, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading and trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  swapcase(self, /)\n",
      " |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      " |  \n",
      " |  title(self, /)\n",
      " |      Return a version of the string where each word is titlecased.\n",
      " |      \n",
      " |      More specifically, words start with uppercased characters and all remaining\n",
      " |      cased characters have lower case.\n",
      " |  \n",
      " |  translate(self, table, /)\n",
      " |      Replace each character in the string using the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a mapping of Unicode ordinals to\n",
      " |          Unicode ordinals, strings, or None.\n",
      " |      \n",
      " |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      " |      dictionary or list.  If this operation raises LookupError, the character is\n",
      " |      left untouched.  Characters mapped to None are deleted.\n",
      " |  \n",
      " |  upper(self, /)\n",
      " |      Return a copy of the string converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  maketrans(...)\n",
      " |      Return a translation table usable for str.translate().\n",
      " |      \n",
      " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      " |      Character keys will be then converted to ordinals.\n",
      " |      If there are two arguments, they must be strings of equal length, and\n",
      " |      in the resulting dictionary, each character in x will be mapped to the\n",
      " |      character at the same position in y. If there is a third argument, it\n",
      " |      must be a string, whose characters will be mapped to None in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26a39e9-6437-4cbe-9d00-b78655ceb825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They',\n",
       " 'told',\n",
       " 'that',\n",
       " 'their',\n",
       " 'ages',\n",
       " 'are',\n",
       " '25',\n",
       " '27',\n",
       " 'and',\n",
       " '31',\n",
       " 'respectively.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "smpl_lst = sent.split(' ')\n",
    "smpl_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577da765-c12c-4c28-997e-dcdaf1a79209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lst = []\n",
    "sum = 0\n",
    "for i in smpl_lst :\n",
    "    if i.isdigit() :\n",
    "        num = int(i)\n",
    "        num_lst.append(num)\n",
    "        sum += num\n",
    "        \n",
    "num_lst\n",
    "avg = sum / len(num_lst)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61350e36-5572-4902-9de5-8db4f1b6856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for word in sent.split() :\n",
    "    if word.isdigit() :\n",
    "        ages.append(int(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24add41f-d0d4-4584-a6df-fa172eb0ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ages) / len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9382fb-f230-480c-bb64-90a5f1d16b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = [int(word) for word in sent.split() if word.isdigit()]\n",
    "avg = np.sum(ages) / len(ages)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08872e93-3309-45d9-8634-a1d550737e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([int(word) for word in sent.split() if word.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df16b8-8a44-4b9d-85b4-7dfd75089565",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad1bb4ca-576b-4242-8ea2-7ebe6bac3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Hello friends! How are you? Welcome to Python Programming.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "207b6eb2-0961-4fdc-8147-f0909aa634df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you?', 'Welcome to Python Programming.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#segmentation\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e6e9f38-7cd1-4af2-9f84-d840166d5ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = word_tokenize(sent)\n",
    "lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d206a1c-9f30-4762-87d7-e9d08f578dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find percentage of punctuation symbols present in it\n",
    "# method 1\n",
    "countpun = 0\n",
    "for i in lst1 :\n",
    "    if  i.isalnum() == False:\n",
    "        countpun+=1\n",
    "per =  (countpun / len(lst1)) * 100\n",
    "per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4da0c96d-5ef3-48cb-b517-a7b111eb3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_count = len([word for word in word_tokenize(sent) if not word.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3deb0eb0-cb43-4545-8f5d-31249c120ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_count / len(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40dac2dd-1a3e-45db-89fa-b23e75e90650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a6fc063-d0e4-447a-98fe-2e4807867ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('#')  #gives ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb9aa660-2133-4147-88c8-e0cda41192f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives how much memory required in bytes\n",
    "sys.getsizeof('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92315bf0-26a2-4180-9a35-4b21484ab9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function getsizeof in module sys:\n",
      "\n",
      "getsizeof(...)\n",
      "    getsizeof(object [, default]) -> int\n",
      "    \n",
      "    Return the size of object in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b980fcba-4b95-48ec-880b-4e0c880c5fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = 'abcdge'\n",
    "sys.getsizeof(char)  # here minimum of 50 is assigned and increases with added characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4614dede-5992-494d-8ccb-7bbecdeec438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(67) #from ascii to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3169a0f-4e8e-43c7-8626-57f2be1bd8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "वी\n",
      "स\n"
     ]
    }
   ],
   "source": [
    "char = '\\u0935\\u0940'  #unicode for devnagari\n",
    "print(char)\n",
    "char1 = '\\u0938'\n",
    "print(char1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38ebc493-c931-4385-86c5-139314f7e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2357"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3fb406d-7167-4265-8746-850124200a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'श'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "937c5288-2790-45f5-8c47-103659a0f00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'व'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x935)   #hexadecimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f3ad023-94b0-4a0c-b1ed-ac03eb55deee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof('व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fde26833-3b51-4560-a9cf-f4a741b64e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'मिताली गिरी'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9074fc14-792b-44f7-bc79-cf58d2e2a789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['मिताली', 'गिरी']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4144ff3-aac2-4dcc-b51a-73d508c7ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.startswith('म')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d52dff6-cca6-41a2-8337-ca5c86265227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मीताली गिरी'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace('मि', 'मी')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c9187aa-b51f-48c8-b8f6-c1d10bc20583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.find('ग')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47e1a97b-e8a6-4f9c-8fa6-fc3b3730ce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39ae17dd-9667-4192-872c-f0e81b15ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ 'मिताली', 'मृणाल', 'अंगिरा', 'तुलसी', 'प्रचेत', 'अमेय', 'प्रणव' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ce9ada6-2e23-46db-9816-713a4a8e782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "प्रचेत\n",
      "प्रणव\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    if name.startswith('प्र'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2eee6a6-9acd-46f2-bc47-082877e46b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtext = 'इतिहास - राजगड किल्ला इसवी सनाच्या पहिल्या शतकातला आहे. या मुरूंबदेवाच्या डोंगराला किल्ल्याचे स्वरूप गौतमीपुत्र सातकर्णी म्हणजेच शालिवाहन राजा ज्याने युद्धात शकांना हारवून इ.स ७८ साली स्वतःच्या नावाचं शक सुरू केले, यानेच आठ वर्षांपूर्वी इ.स ७० साली ह्या मुरूंबदेवाच्या डोंगरावर सुंदर असा व उंचपुरा राजगड किल्ला बांधला. बहुधा सन १६४५ मध्ये शिवाजी महाराजांनी हा किल्ला ताब्यात घेऊन त्यावर बांधकाम केले व त्याचे नाव राजगड ठेवले. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69c484b8-9762-4009-9424-812122bfc3cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['इतिहास',\n",
       " '-',\n",
       " 'राजगड',\n",
       " 'किल्ला',\n",
       " 'इसवी',\n",
       " 'सनाच्या',\n",
       " 'पहिल्या',\n",
       " 'शतकातला',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'या',\n",
       " 'मुरूंबदेवाच्या',\n",
       " 'डोंगराला',\n",
       " 'किल्ल्याचे',\n",
       " 'स्वरूप',\n",
       " 'गौतमीपुत्र',\n",
       " 'सातकर्णी',\n",
       " 'म्हणजेच',\n",
       " 'शालिवाहन',\n",
       " 'राजा',\n",
       " 'ज्याने',\n",
       " 'युद्धात',\n",
       " 'शकांना',\n",
       " 'हारवून',\n",
       " 'इ.स',\n",
       " '७८',\n",
       " 'साली',\n",
       " 'स्वतःच्या',\n",
       " 'नावाचं',\n",
       " 'शक',\n",
       " 'सुरू',\n",
       " 'केले',\n",
       " ',',\n",
       " 'यानेच',\n",
       " 'आठ',\n",
       " 'वर्षांपूर्वी',\n",
       " 'इ.स',\n",
       " '७०',\n",
       " 'साली',\n",
       " 'ह्या',\n",
       " 'मुरूंबदेवाच्या',\n",
       " 'डोंगरावर',\n",
       " 'सुंदर',\n",
       " 'असा',\n",
       " 'व',\n",
       " 'उंचपुरा',\n",
       " 'राजगड',\n",
       " 'किल्ला',\n",
       " 'बांधला',\n",
       " '.',\n",
       " 'बहुधा',\n",
       " 'सन',\n",
       " '१६४५',\n",
       " 'मध्ये',\n",
       " 'शिवाजी',\n",
       " 'महाराजांनी',\n",
       " 'हा',\n",
       " 'किल्ला',\n",
       " 'ताब्यात',\n",
       " 'घेऊन',\n",
       " 'त्यावर',\n",
       " 'बांधकाम',\n",
       " 'केले',\n",
       " 'व',\n",
       " 'त्याचे',\n",
       " 'नाव',\n",
       " 'राजगड',\n",
       " 'ठेवले',\n",
       " '.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(mtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50ef09ab-ad16-4f46-887e-ae29b75d76b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['इतिहास - राजगड किल्ला इसवी सनाच्या पहिल्या शतकातला आहे.',\n",
       " 'या मुरूंबदेवाच्या डोंगराला किल्ल्याचे स्वरूप गौतमीपुत्र सातकर्णी म्हणजेच शालिवाहन राजा ज्याने युद्धात शकांना हारवून इ.स ७८ साली स्वतःच्या नावाचं शक सुरू केले, यानेच आठ वर्षांपूर्वी इ.स ७० साली ह्या मुरूंबदेवाच्या डोंगरावर सुंदर असा व उंचपुरा राजगड किल्ला बांधला.',\n",
       " 'बहुधा सन १६४५ मध्ये शिवाजी महाराजांनी हा किल्ला ताब्यात घेऊन त्यावर बांधकाम केले व त्याचे नाव राजगड ठेवले.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(mtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaaf1d2-f8eb-4c88-9ab0-18be6b59e113",
   "metadata": {},
   "source": [
    "## 1. Space tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91be9199-db87-49b4-aad7-fd82d370dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('mydata.txt', encoding='utf-8')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ce81d19-bd8f-4acf-a8dd-5a3119d728fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!😎How are you?👻\n",
      "Welcome🐧 to the world🌍 of Python Programming.🐍\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d190599-48a0-479e-86e1-f7414635197e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!😎How',\n",
       " 'are',\n",
       " 'you?👻\\nWelcome🐧',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world🌍',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming.🐍']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "#tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa097f9-20fc-4a88-8e45-43dcb9394467",
   "metadata": {},
   "source": [
    "## 2. Tab tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7696dbd3-6078-469c-88cb-fea95a2f7d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!😎How are you?👻\n",
      "Welcome🐧 to the world🌍 of Python Programming.🐍\n"
     ]
    }
   ],
   "source": [
    "f = open('mydata.txt', encoding='utf-8')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbf28d04-314c-4bb8-86b2-2ebe77fbb188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends!😎How are you?👻\\nWelcome🐧 to the world🌍 of Python Programming.🐍']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "tbk = TabTokenizer()\n",
    "\n",
    "#tokenize the data\n",
    "tbk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1350785-fe15-4927-ab56-61a2aaec1fe4",
   "metadata": {},
   "source": [
    "## 3. Line Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64a98cc4-7e34-48af-a9d9-c1f121c7be56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends!😎How are you?👻',\n",
       " 'Welcome🐧 to the world🌍 of Python Programming.🐍']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "lt = LineTokenizer()\n",
    "\n",
    "#tokenize the data\n",
    "lt.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa5674-853d-4519-8aaf-946ad9d051e3",
   "metadata": {},
   "source": [
    "## 4. White Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c48df367-3ab2-4b1a-9e7a-c95a13310b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!😎How',\n",
       " 'are',\n",
       " 'you?👻',\n",
       " 'Welcome🐧',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world🌍',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming.🐍']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "wst = WhitespaceTokenizer()  #like split considers all three spaces- space, tab, newline\n",
    "\n",
    "#tokenize the data\n",
    "wst.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bafc8b-b424-49cd-ad0d-c09ed6ea7427",
   "metadata": {},
   "source": [
    "## 5. MWE Tokenizer (Multi word expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a842748-cb7f-48f5-aacc-0524d3d518db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Van Rossum is Python creator, visiting Pune this week. The development community is very eager to meet Van Rossum.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'The Van Rossum is Python creator, visiting Pune this week. The development community is very eager to meet Van Rossum.'\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3ddf99a-42a0-42a2-b357-aca66e23f275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visiting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'development',\n",
       " 'community',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1882cf7-4ac1-4c9a-b2dd-60debf4af511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visiting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'development',\n",
       " 'community',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "tk = MWETokenizer(separator=' ')  #when we want two words to be together as same token\n",
    "\n",
    "#add multi word expression\n",
    "tk.add_mwe(('Van','Rossum'))\n",
    "\n",
    "#tokenize the data\n",
    "tk.tokenize(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d8f38-9683-44e3-91b0-9646115186af",
   "metadata": {},
   "source": [
    "## 6. Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "430bf99e-662f-429c-90ed-72acb2273e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends :)! How are you? Welcome to the world of Python Programming. :D\n"
     ]
    }
   ],
   "source": [
    "sent = 'Hello Friends :)! How are you? Welcome to the world of Python Programming. :D'\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3883a2c2-614a-486a-b5c4-f44751ef1bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " ':)',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.',\n",
       " ':D']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "tk = TweetTokenizer()  \n",
    "\n",
    "#tokenize the data\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb21cf95-35dd-40de-900a-7b51d5bc4ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!😎How are you?👻\n",
      "Welcome🐧 to the world🌍 of Python Programming.🐍\n"
     ]
    }
   ],
   "source": [
    "f = open('mydata.txt',encoding='utf-8')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a056271f-88b3-4ee1-a23d-faeec9e17268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '!',\n",
       " '😎',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '👻',\n",
       " 'Welcome',\n",
       " '🐧',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " '🌍',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.',\n",
       " '🐍']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the object\n",
    "tk = TweetTokenizer()  \n",
    "\n",
    "#tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb15d322-6c6b-472d-9bc6-47a94d17f40a",
   "metadata": {},
   "source": [
    "## 7. Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75bdfc60-0a61-4287-aa74-b757eac9d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "This is some text\n",
      " with punctuation\n",
      "  > Let's tokenize it\n",
      " Is it ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,:?]+\", text)\n",
    "\n",
    "text = \"This is some text? with punctuation.  > Let's tokenize it. Is it ok?\"\n",
    "\n",
    "tokens = custom_tokenizer(text)\n",
    "\n",
    "print(\"Tokens:\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d9324d9-aec5-49b6-8cb9-1e248376b6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roll\tname\tclass\tmarks\tage\n",
      "1\tanil\tTE\t56.77\t22\n",
      "2\tamit\tTE\t59.77\t21\n",
      "3\taniket\tBE\t76.88\t19\n",
      "4\tajinkya\tTE\t69.66\t20\n",
      "5\tasha\tTE\t63.28\t20\n",
      "6\tayesha\tBE\t49.55\t20\n",
      "7\tamar\tBE\t65.34\t19\n",
      "8\tamita\tBE\t68.33\t23\n",
      "9\tamol\tTE\t56.75\t20\n",
      "10\tanmol\tBE\t78.66\t21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('student3.tsv')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c90e9be-6424-4021-8dfc-4280467c4306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'anil', 'TE', 56.77, 22],\n",
       " [2, 'amit', 'TE', 59.77, 21],\n",
       " [3, 'aniket', 'BE', 76.88, 19],\n",
       " [4, 'ajinkya', 'TE', 69.66, 20],\n",
       " [5, 'asha', 'TE', 63.28, 20],\n",
       " [6, 'ayesha', 'BE', 49.55, 20],\n",
       " [7, 'amar', 'BE', 65.34, 19],\n",
       " [8, 'amita', 'BE', 68.33, 23],\n",
       " [9, 'amol', 'TE', 56.75, 20],\n",
       " [10, 'anmol', 'BE', 78.66, 21]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"\\n\", text)\n",
    "\n",
    "tokens = custom_tokenizer(data)\n",
    "\n",
    "print(\"Tokens:\")\n",
    "lst = []\n",
    "\n",
    "for token in tokens:\n",
    "    lst.append(word_tokenize(token))\n",
    "\n",
    "lst.pop(0)\n",
    "lst.pop(-1)\n",
    "lst2 = [[int(x[0]), x[1], x[2], float(x[3]), int(x[4])] for x in lst]\n",
    "lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96e54861-2836-4c25-ad85-8f4784c5f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'anil', 'TE', 56.77, 22],\n",
       " [2, 'amit', 'TE', 59.77, 21],\n",
       " [3, 'aniket', 'BE', 76.88, 19],\n",
       " [4, 'ajinkya', 'TE', 69.66, 20],\n",
       " [5, 'asha', 'TE', 63.28, 20],\n",
       " [6, 'ayesha', 'BE', 49.55, 20],\n",
       " [7, 'amar', 'BE', 65.34, 19],\n",
       " [8, 'amita', 'BE', 68.33, 23],\n",
       " [9, 'amol', 'TE', 56.75, 20],\n",
       " [10, 'anmol', 'BE', 78.66, 21]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = []\n",
    "\n",
    "for x in data.split('\\n'):\n",
    "    inner_list = []\n",
    "    for y in x.split('\\t'):\n",
    "        if y.isdigit():\n",
    "            inner_list.append(int(y))\n",
    "        elif y.find('.') > 0 :\n",
    "            inner_list.append(float(y))\n",
    "        else :\n",
    "            inner_list.append(y)\n",
    "    new_data.append(inner_list)\n",
    "\n",
    "new_data.pop(0)\n",
    "new_data.pop(-1)\n",
    "new_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
