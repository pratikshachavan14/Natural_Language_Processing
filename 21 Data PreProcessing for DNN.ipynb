{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770760e6-1e9c-46ca-b639-6d41b7241da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import the libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c58a47b-fa35-4f7d-86ef-ec1dbd5923b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was a nice rainy day.',\n",
       " 'The things are so beautiful in his point',\n",
       " 'When your focus is clear, you won.',\n",
       " 'Many many happy returns of the day.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines =['It was a nice rainy day.','The things are so beautiful in his point', 'When your focus is clear, you won.', 'Many many happy returns of the day.']\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f822ba-5e14-4d15-8163-b4950dd59dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 1,\n",
       " 'the': 2,\n",
       " 'many': 3,\n",
       " 'it': 4,\n",
       " 'was': 5,\n",
       " 'a': 6,\n",
       " 'nice': 7,\n",
       " 'rainy': 8,\n",
       " 'things': 9,\n",
       " 'are': 10,\n",
       " 'so': 11,\n",
       " 'beautiful': 12,\n",
       " 'in': 13,\n",
       " 'his': 14,\n",
       " 'point': 15,\n",
       " 'when': 16,\n",
       " 'your': 17,\n",
       " 'focus': 18,\n",
       " 'is': 19,\n",
       " 'clear': 20,\n",
       " 'you': 21,\n",
       " 'won': 22,\n",
       " 'happy': 23,\n",
       " 'returns': 24,\n",
       " 'of': 25}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9a2933-e704-4d9e-8269-e26c6f23c4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = tokenizer.texts_to_matrix(lines)\n",
    "mat     \n",
    "\n",
    "#tokenizer.word_index from this has 25 words and where its 1 then that word present of of 0 word not present in that sentence \n",
    "#we have 4 sentences in line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2df9b8-7597-4ee8-be37-4b6eab472ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aec97fd-6653-4607-859e-2e383759a880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 5, 6, 7, 8, 1],\n",
       " [2, 9, 10, 11, 12, 13, 14, 15],\n",
       " [16, 17, 18, 19, 20, 21, 22],\n",
       " [3, 3, 23, 24, 25, 2, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = tokenizer.texts_to_sequences(lines)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac7010a-b48a-4922-a670-afa735d61106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6,  7,  8,  1,  0,  0,  0,  0],\n",
       "       [ 2,  9, 10, 11, 12, 13, 14, 15,  0,  0],\n",
       "       [16, 17, 18, 19, 20, 21, 22,  0,  0,  0],\n",
       "       [ 3,  3, 23, 24, 25,  2,  1,  0,  0,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pad sequence \n",
    "padded = pad_sequences(seq, maxlen=10, padding='post')   #padding two types-> post, pre\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568d6dfa-5be0-4409-b5db-6b03f156f99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d668d12-586e-436b-9bcf-b0a5430e6c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  4,  5,  6,  7,  8,  1],\n",
       "       [ 0,  0,  2,  9, 10, 11, 12, 13, 14, 15],\n",
       "       [ 0,  0,  0, 16, 17, 18, 19, 20, 21, 22],\n",
       "       [ 0,  0,  0,  3,  3, 23, 24, 25,  2,  1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pad sequence \n",
    "padded = pad_sequences(seq, maxlen=10, padding='pre')   #padding two types-> post, pre\n",
    "padded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
